[
  {
    "objectID": "sop.html",
    "href": "sop.html",
    "title": "Procedure",
    "section": "",
    "text": "The following scripts are to be run on a site’s full OMOP dataset in order to prepare the relevant data for sharing with the VIRUS registry. Each script should be run on the same server as the OMOP data but can be customized to run on the preferred Database and Schema.\nInstructions: Replace the database name and schema in each of these scripts with your own, then run the cohort creation and deidentification scripts in the following sequence:\n\n\nFilename: 00_CURE_ID_create_concept_table.sql)\nPurpose: This script creates a table of standard concepts required for the CureID Registry project. It is used in conjunction with CONCEPT_ANCESTOR table in 02_CURE_ID_All_Tables.sql script.\nDescription: Fields particularly important to the process are “is_standard” and “include_descendants”.\n“is_standard” determines the standardization of the concept, either: a “C”, “S”, or “N” – C is for classification. This concept will not be used, but it may have useable descendants – S is for Standard. These codes will be used. They may or may not have descendants – N is Non-standard. These codes will not be used. If they have descendants\n“include_descendants” determines whether the script should look for descendents – Values are either TRUE or FALSE\nThey will be used in 02_CURE_ID_All_Tables.sql in the FROM clauses: Measurement example: INNER JOIN omop.CONCEPT_ANCESTOR ON descendant_concept_id = m.measurement_concept_id INNER JOIN [Results].[cure_id_concepts] ON ancestor_concept_id = concept_id WHERE domain = ‘Measurement’ AND (include_descendants = ‘TRUE’ OR ancestor_concept_id = descendant_concept_id)\nIf “include_descendants” is either ‘TRUE’ or if the ancestor_concept_id is the same as descendant_concept_id, the concept will be used. The “is_standard” field is informational only and does not participate in the script.\nDependencies: None\n\n\n\nFilename: 01_CURE_ID_Cohort.sql\nPurpose: This script creates a cohort of patients for the CURE ID registry. The patient list is saved in the cohort table, along with other useful data elements.\nDescription: This SQL script creates a cohort of COVID-positive hospitalized patients based on specific criteria. The script performs several steps to identify and filter the patients before finally creating the cohort table. The script sets the context to use a specific database, but the actual name of the database is meant to be provided by the user.\nDependencies: None\nSteps:\n\nCreate cohort table.\nIdentify patients (inpatient and outpatient) with covid positive lab results\n\nUse OMOP concepts that represent the LOINC codes for SARS-COV-2 nucleic acid test\nThe concept ids here represent LOINC or SNOMED codes for standard ways to code a lab that is positive.\n\nIdentify the first positive covid test per patient (after January 1, 2020).\nLimit to covid-positive patients with inpatient encounters.\nApply all inclusion/exclusion criteria to identify all patients hospitalized with symptomatic covid-19 up to 21 days after a positive SARS-CoV-2 test or up to 7 days prior to a positive SARS-CoV-2 test\nFind the closest inpatient encounter to first positive SARS-COV-2 test (for patients hospitalized more than once)\nAccount for edge cases where patients have two hospitalizations same number of absolute days from SARS-COV-2 test (Ex: Patient hospitalized separately 3 days before and 3 days after SARS-COV-2 test)\nCreate the cohort by adding on birth date and death date\n\n\n\n\nFilename: 02_CURE_ID_All_Tables.sql\nPurpose: This script takes your OMOP dataset and generates a copy of key tables that have been filtered down to only include people and records related to the CURE ID registry.\nDescription: Creates CURE_ID tables from the generated CURE_ID cohort.\nDependencies: - 01_CURE_ID_Cohort.sql\nSteps:\n\nLoad Person table\nLoad Measurements table\nLoad Drug Exposure table\nLoad Death table\nLoad Observation data\nLoad Procedure Occurrence Table\nLoad Condition Occurrence Table\nLoad Visit Occurrence table\nLoad Device Exposure tabledb\n\n\n\n\nFilename: 03_CURE_ID_replace_rare_conditions_with_parents.sql\nPurpose: Replace conditions occurring 10 or less times in the dataset with parent concepts that have at least 10 counts\nDescription: This script is run after scripts 01 and 02\nDependencies: - 01_CURE_ID_Cohort.sql - 02_CURE_ID_All_Tables.sql\nSteps:\n\nCondition roll up: concepts are mapped to their corresponding ancestor concept(s)\nCreate table that counts the ancestor concepts for each original concept\nCreate table that counts the original concepts\nFilter to only include conditions that have more than 10 counts\nGet just the most specific condition in the ancestor-descendent hierarchy\n\n\n\n\nFilename: 04_DE_ID_CDM_Table_ddl.sql\nPurpose: Generate the necessary tables for the de-identified version of the CURE ID Cohort\nDescription: This script will create tables in the Results schema and preface the table names with ‘deident.’ However, the preface can be set to whatever value you desire.\nDependencies: None\nSteps:\n\nCreate the Person table\nCreate the Death table\nCreate the Visit Occurrence table\nCreate the Drug Exposure table\nCreate the Device Exposure table\nCreate the Condition Occurrence table\nCreate the Measurement table\nCreate the Observation table\n\n\n\n\nFilename: 05_DE_ID_script.sql\nPurpose: This script creates a copy of the Cohort and removes identifying characteristics to prepare the data for sharing with the VIRUS registry.\nDescription: Run this script to generate a deidentified copy of your target data. The following actions are performed: - Reassignment of Person IDs: Person IDs are regenerated sequentially from a sorted copy of the Person table. These new Person IDs are carried throughout the CDM to all tables that reference it.\n\nDate Shifting: Each person is assigned a random date shift value between -186 and +186 days. All dates for that person are then shifted shifted by that amount.\nBirthdays: After date shifting a person’s birthday, the day is then set to the first of the new birth month. If the person would be &gt; 89 years old then they are assigned a random birth year that would make them 90-99 years old.\nDate Truncation: A user-defined Start and End date are used to exclude any date shifted data that falls outside of the target date range (e.g. procedures, conditions occurrences, etc.). Does not include Birthdates.\nRemoval of Other Identifiers: Other potentially identifying datapoints are removed from the dataset such as location_id, provider_id, and care_site_id\n\nDependencies: - 01_CURE_ID_Cohort.sql - 02_CURE_ID_All_Tables.sql - 03_CURE_ID_replace_rare_conditions_with_parents.sql - 04_DE_ID_CDM_Table_ddl.sql\nSteps:\n\nUse find and replace to set source and target DB and Schema names\nLoad the OMOP Person table, and de-identify\nLoad the OMOP Visit Occurrence table, and de-identify\nLoad the OMOP Condition Occurrence table, and de-identify\nLoad the OMOP Procedure Occurrence table, and de-identify\nLoad the OMOP Drug Exposure table, and de-identify\nLoad the OMOP Observation table, and de-identify\nLoad the OMOP Death table, and de-identify\nLoad the OMOP Device Exposure table, and de-identify\nLoad the OMOP Measurement table, and de-identify\n\n\n\n\nFilename: 06_DE_ID_Quality_Checks.sql\nPurpose: This script checks basic metrics for each table in the deidentified dataset to ensure the previous scripts were successful.\nDescription: This script runs a number of summary level quality checks for each table to audit basic data counts and date ranges.\nDependencies: - 01_CURE_ID_Cohort.sql - 02_CURE_ID_All_Tables.sql - 03_CURE_ID_replace_rare_conditions_with_parents.sql - 04_DE_ID_CDM_Table_ddl.sql - 05_DE_ID_script.sql\nSteps:\n\nCount distinct person_ids and find the maximum and minimum birthdates in the OMOP Person table.\nCount distinct person_ids in the OMOP Death table.\nCount distinct person_ids, count number of records per observation_concept_id, and find the maximum and minimum observation dates for all records in the OMOP Observation table.\nCount distinct person_ids, count number of records per procedure_concept_id, and find the maximum and minimum procedure dates for all records in the OMOP Procedure Occurrence table.\nCount distinct person_ids, count number of records per condition_concept_id, and find the maximum and minimum condition dates for all records in the OMOP Condition Occurrence table.\nCount distinct person_ids, count number of records per measurement_concept_id, and find the maximum and minimum measurement dates for all records in the OMOP Measurement table.\nCount distinct person_ids, count number of records per device_concept_id, and find the maximum and minimum device exposure dates for all records in the OMOP Device Exposure table.\nCount distinct person_ids, count number of records per drug_concept_id, and find the maximum and minimum drug exposure dates for all records in the OMOP Drug Exposure table.\n\n\n\n\nDependencies: These scripts require the populated deidentified OMOP tables generated from the sequence of running scripts 1-5:\n\n01_CURE_ID_Cohort.sql\n02_CURE_ID_All_Tables.sql\n03_CURE_ID_replace_rare_conditions_with_parents.sql\n04_DE_ID_CDM_Table_ddl.sql\n05_DE_ID_script.sql\n##### 07-A – Condition Profile\nFilename: 07_A_condition_profile.sql\nPurpose: Generate a profile of condition prevalence in the final cohort.\nDescription: Condition counts are calculated per patient and are aggregated by parent concepts for each condition concept present in the final OMOP Condition Occurrence table.\n##### 07-B – Measurement Profile\nFilename: 07_B_measurement_profile.sql\nPurpose: Generate a profile of measurement prevalence in the final cohort.\nDescription: Measurement counts are calculated per patient and are aggregated by parent concepts for each measurement concept present in the final OMOP Measurement table.\n##### 07-C – Drug Exposure Profile\nFilename: 07_C_drug_exposure_profile.sql\nPurpose: Generate a profile of drug prevalence in the final cohort.\nDescription: Drug counts are calculated per patient and are aggregated by ingredient for each drug concept present in the final OMOP Drug Exposure table.\n##### 07-D – Unmapped Drugs Profile\nFilename: 07_D_review_unmapped_drugs.sql\nPurpose: Generate a profile of drugs that are not mapped to drug_concept_ids in the final cohort.\nDescription: This file filters drugs that were unsuccessfully mapped to a drug_concept_id when running the 02_CURE_ID_All_Tables.sql script. Drug source values for which the drug_concept_id is “0” and have at least 20 instances in the final cohort are aggregated for manual review. ** Drug source values can contain PHI. Please review the output for PHI before sharing.\n##### 07-E – Device Profile\nFilename: 07_E_device_profile.sql\nPurpose: Generate a profile of device prevalence in the final cohort.\nDescription: Device counts are calculated per patient and are aggregated by parent concepts for each device concept present in the final OMOP Device Exposure table.",
    "crumbs": [
      "Process",
      "Procedure"
    ]
  },
  {
    "objectID": "sop.html#omop-cohort-creation-and-de-identification-guide",
    "href": "sop.html#omop-cohort-creation-and-de-identification-guide",
    "title": "Procedure",
    "section": "",
    "text": "The following scripts are to be run on a site’s full OMOP dataset in order to prepare the relevant data for sharing with the VIRUS registry. Each script should be run on the same server as the OMOP data but can be customized to run on the preferred Database and Schema.\nInstructions: Replace the database name and schema in each of these scripts with your own, then run the cohort creation and deidentification scripts in the following sequence:\n\n\nFilename: 00_CURE_ID_create_concept_table.sql)\nPurpose: This script creates a table of standard concepts required for the CureID Registry project. It is used in conjunction with CONCEPT_ANCESTOR table in 02_CURE_ID_All_Tables.sql script.\nDescription: Fields particularly important to the process are “is_standard” and “include_descendants”.\n“is_standard” determines the standardization of the concept, either: a “C”, “S”, or “N” – C is for classification. This concept will not be used, but it may have useable descendants – S is for Standard. These codes will be used. They may or may not have descendants – N is Non-standard. These codes will not be used. If they have descendants\n“include_descendants” determines whether the script should look for descendents – Values are either TRUE or FALSE\nThey will be used in 02_CURE_ID_All_Tables.sql in the FROM clauses: Measurement example: INNER JOIN omop.CONCEPT_ANCESTOR ON descendant_concept_id = m.measurement_concept_id INNER JOIN [Results].[cure_id_concepts] ON ancestor_concept_id = concept_id WHERE domain = ‘Measurement’ AND (include_descendants = ‘TRUE’ OR ancestor_concept_id = descendant_concept_id)\nIf “include_descendants” is either ‘TRUE’ or if the ancestor_concept_id is the same as descendant_concept_id, the concept will be used. The “is_standard” field is informational only and does not participate in the script.\nDependencies: None\n\n\n\nFilename: 01_CURE_ID_Cohort.sql\nPurpose: This script creates a cohort of patients for the CURE ID registry. The patient list is saved in the cohort table, along with other useful data elements.\nDescription: This SQL script creates a cohort of COVID-positive hospitalized patients based on specific criteria. The script performs several steps to identify and filter the patients before finally creating the cohort table. The script sets the context to use a specific database, but the actual name of the database is meant to be provided by the user.\nDependencies: None\nSteps:\n\nCreate cohort table.\nIdentify patients (inpatient and outpatient) with covid positive lab results\n\nUse OMOP concepts that represent the LOINC codes for SARS-COV-2 nucleic acid test\nThe concept ids here represent LOINC or SNOMED codes for standard ways to code a lab that is positive.\n\nIdentify the first positive covid test per patient (after January 1, 2020).\nLimit to covid-positive patients with inpatient encounters.\nApply all inclusion/exclusion criteria to identify all patients hospitalized with symptomatic covid-19 up to 21 days after a positive SARS-CoV-2 test or up to 7 days prior to a positive SARS-CoV-2 test\nFind the closest inpatient encounter to first positive SARS-COV-2 test (for patients hospitalized more than once)\nAccount for edge cases where patients have two hospitalizations same number of absolute days from SARS-COV-2 test (Ex: Patient hospitalized separately 3 days before and 3 days after SARS-COV-2 test)\nCreate the cohort by adding on birth date and death date\n\n\n\n\nFilename: 02_CURE_ID_All_Tables.sql\nPurpose: This script takes your OMOP dataset and generates a copy of key tables that have been filtered down to only include people and records related to the CURE ID registry.\nDescription: Creates CURE_ID tables from the generated CURE_ID cohort.\nDependencies: - 01_CURE_ID_Cohort.sql\nSteps:\n\nLoad Person table\nLoad Measurements table\nLoad Drug Exposure table\nLoad Death table\nLoad Observation data\nLoad Procedure Occurrence Table\nLoad Condition Occurrence Table\nLoad Visit Occurrence table\nLoad Device Exposure tabledb\n\n\n\n\nFilename: 03_CURE_ID_replace_rare_conditions_with_parents.sql\nPurpose: Replace conditions occurring 10 or less times in the dataset with parent concepts that have at least 10 counts\nDescription: This script is run after scripts 01 and 02\nDependencies: - 01_CURE_ID_Cohort.sql - 02_CURE_ID_All_Tables.sql\nSteps:\n\nCondition roll up: concepts are mapped to their corresponding ancestor concept(s)\nCreate table that counts the ancestor concepts for each original concept\nCreate table that counts the original concepts\nFilter to only include conditions that have more than 10 counts\nGet just the most specific condition in the ancestor-descendent hierarchy\n\n\n\n\nFilename: 04_DE_ID_CDM_Table_ddl.sql\nPurpose: Generate the necessary tables for the de-identified version of the CURE ID Cohort\nDescription: This script will create tables in the Results schema and preface the table names with ‘deident.’ However, the preface can be set to whatever value you desire.\nDependencies: None\nSteps:\n\nCreate the Person table\nCreate the Death table\nCreate the Visit Occurrence table\nCreate the Drug Exposure table\nCreate the Device Exposure table\nCreate the Condition Occurrence table\nCreate the Measurement table\nCreate the Observation table\n\n\n\n\nFilename: 05_DE_ID_script.sql\nPurpose: This script creates a copy of the Cohort and removes identifying characteristics to prepare the data for sharing with the VIRUS registry.\nDescription: Run this script to generate a deidentified copy of your target data. The following actions are performed: - Reassignment of Person IDs: Person IDs are regenerated sequentially from a sorted copy of the Person table. These new Person IDs are carried throughout the CDM to all tables that reference it.\n\nDate Shifting: Each person is assigned a random date shift value between -186 and +186 days. All dates for that person are then shifted shifted by that amount.\nBirthdays: After date shifting a person’s birthday, the day is then set to the first of the new birth month. If the person would be &gt; 89 years old then they are assigned a random birth year that would make them 90-99 years old.\nDate Truncation: A user-defined Start and End date are used to exclude any date shifted data that falls outside of the target date range (e.g. procedures, conditions occurrences, etc.). Does not include Birthdates.\nRemoval of Other Identifiers: Other potentially identifying datapoints are removed from the dataset such as location_id, provider_id, and care_site_id\n\nDependencies: - 01_CURE_ID_Cohort.sql - 02_CURE_ID_All_Tables.sql - 03_CURE_ID_replace_rare_conditions_with_parents.sql - 04_DE_ID_CDM_Table_ddl.sql\nSteps:\n\nUse find and replace to set source and target DB and Schema names\nLoad the OMOP Person table, and de-identify\nLoad the OMOP Visit Occurrence table, and de-identify\nLoad the OMOP Condition Occurrence table, and de-identify\nLoad the OMOP Procedure Occurrence table, and de-identify\nLoad the OMOP Drug Exposure table, and de-identify\nLoad the OMOP Observation table, and de-identify\nLoad the OMOP Death table, and de-identify\nLoad the OMOP Device Exposure table, and de-identify\nLoad the OMOP Measurement table, and de-identify\n\n\n\n\nFilename: 06_DE_ID_Quality_Checks.sql\nPurpose: This script checks basic metrics for each table in the deidentified dataset to ensure the previous scripts were successful.\nDescription: This script runs a number of summary level quality checks for each table to audit basic data counts and date ranges.\nDependencies: - 01_CURE_ID_Cohort.sql - 02_CURE_ID_All_Tables.sql - 03_CURE_ID_replace_rare_conditions_with_parents.sql - 04_DE_ID_CDM_Table_ddl.sql - 05_DE_ID_script.sql\nSteps:\n\nCount distinct person_ids and find the maximum and minimum birthdates in the OMOP Person table.\nCount distinct person_ids in the OMOP Death table.\nCount distinct person_ids, count number of records per observation_concept_id, and find the maximum and minimum observation dates for all records in the OMOP Observation table.\nCount distinct person_ids, count number of records per procedure_concept_id, and find the maximum and minimum procedure dates for all records in the OMOP Procedure Occurrence table.\nCount distinct person_ids, count number of records per condition_concept_id, and find the maximum and minimum condition dates for all records in the OMOP Condition Occurrence table.\nCount distinct person_ids, count number of records per measurement_concept_id, and find the maximum and minimum measurement dates for all records in the OMOP Measurement table.\nCount distinct person_ids, count number of records per device_concept_id, and find the maximum and minimum device exposure dates for all records in the OMOP Device Exposure table.\nCount distinct person_ids, count number of records per drug_concept_id, and find the maximum and minimum drug exposure dates for all records in the OMOP Drug Exposure table.\n\n\n\n\nDependencies: These scripts require the populated deidentified OMOP tables generated from the sequence of running scripts 1-5:\n\n01_CURE_ID_Cohort.sql\n02_CURE_ID_All_Tables.sql\n03_CURE_ID_replace_rare_conditions_with_parents.sql\n04_DE_ID_CDM_Table_ddl.sql\n05_DE_ID_script.sql\n##### 07-A – Condition Profile\nFilename: 07_A_condition_profile.sql\nPurpose: Generate a profile of condition prevalence in the final cohort.\nDescription: Condition counts are calculated per patient and are aggregated by parent concepts for each condition concept present in the final OMOP Condition Occurrence table.\n##### 07-B – Measurement Profile\nFilename: 07_B_measurement_profile.sql\nPurpose: Generate a profile of measurement prevalence in the final cohort.\nDescription: Measurement counts are calculated per patient and are aggregated by parent concepts for each measurement concept present in the final OMOP Measurement table.\n##### 07-C – Drug Exposure Profile\nFilename: 07_C_drug_exposure_profile.sql\nPurpose: Generate a profile of drug prevalence in the final cohort.\nDescription: Drug counts are calculated per patient and are aggregated by ingredient for each drug concept present in the final OMOP Drug Exposure table.\n##### 07-D – Unmapped Drugs Profile\nFilename: 07_D_review_unmapped_drugs.sql\nPurpose: Generate a profile of drugs that are not mapped to drug_concept_ids in the final cohort.\nDescription: This file filters drugs that were unsuccessfully mapped to a drug_concept_id when running the 02_CURE_ID_All_Tables.sql script. Drug source values for which the drug_concept_id is “0” and have at least 20 instances in the final cohort are aggregated for manual review. ** Drug source values can contain PHI. Please review the output for PHI before sharing.\n##### 07-E – Device Profile\nFilename: 07_E_device_profile.sql\nPurpose: Generate a profile of device prevalence in the final cohort.\nDescription: Device counts are calculated per patient and are aggregated by parent concepts for each device concept present in the final OMOP Device Exposure table.",
    "crumbs": [
      "Process",
      "Procedure"
    ]
  },
  {
    "objectID": "interpret.html",
    "href": "interpret.html",
    "title": "Interpretation",
    "section": "",
    "text": "This section provides synthetic examples of the output generated from the CURE ID person measurement drug exposure and device profile SQL scripts as well as examples of how to interpret the output from each script.\n\n\nGenerates a table showing condition prevalence in cohort by individual condition concept.\nExample Interpretation\nIn the highlighted row, the table shows that 6499 patients in the cohort have a recorded diagnosis of hypertension, representing 58% of the total cohort.\n\n\n\nProfile_script_7A\n\n\n\n\n\nGenerates a table which includes the measurement concepts included in the cohort and their names.\nExample Interpretation\nThe highlighted row shows the distribution of the number of times heart rate was measured per patient in the cohort. 25% of the patients had 17 heart rate measurements or less. 50% of patients had at least 34 heart rate measurements recorded. 75% of patients had at most, 72 heart rate measurements recorded. 95% of patients had at most, 398 heart rate measurements recorded. The four columns can also be interpreted as the median for the bottom 50% (percentile_25), overall median (median), median for the top 50% (percentile_75), and the median for the top 10% (percentile_95) – in terms of how many times the measurement was taken for each patient in the cohort.\n\n\n\nProfile_script_7B\n\n\n\n\n\nGenerates a table of all drugs given in the cohort.\nExample Interpretation\nThe highlighted row shows that acetaminophen was administered to 7,937 total patients which represents 68% of the patients in the cohort. Acetaminophen was administered an average of 2 times per patient with the highest recorded value of 26 administrations for a single patient.\nIt is important to note that these are ingredients - which is why sodium chloride is the most frequent “drug” because most IV drugs contain sodium chloride as an ingredient.\n\n\n\nProfile_script_7C\n\n\n\n\n\nGenerates a table which includes the device concepts included in the cohort and their counts.\nExample Interpretation\nThe highlighted row shows that an oxygen nasal cannula device was used for 9,238 patients in the cohort. That patients count represents 44% of the total cohort. Use of this device was recorded an average of 225.3 times per patient, with a maximum of 7,239 recordings for a single patient, when counting all flowsheet entries.\n\n\n\nProfile_script_7E",
    "crumbs": [
      "Process",
      "Interpretation"
    ]
  },
  {
    "objectID": "interpret.html#cure-id-profile-scripts-output-interpretation",
    "href": "interpret.html#cure-id-profile-scripts-output-interpretation",
    "title": "Interpretation",
    "section": "",
    "text": "This section provides synthetic examples of the output generated from the CURE ID person measurement drug exposure and device profile SQL scripts as well as examples of how to interpret the output from each script.\n\n\nGenerates a table showing condition prevalence in cohort by individual condition concept.\nExample Interpretation\nIn the highlighted row, the table shows that 6499 patients in the cohort have a recorded diagnosis of hypertension, representing 58% of the total cohort.\n\n\n\nProfile_script_7A\n\n\n\n\n\nGenerates a table which includes the measurement concepts included in the cohort and their names.\nExample Interpretation\nThe highlighted row shows the distribution of the number of times heart rate was measured per patient in the cohort. 25% of the patients had 17 heart rate measurements or less. 50% of patients had at least 34 heart rate measurements recorded. 75% of patients had at most, 72 heart rate measurements recorded. 95% of patients had at most, 398 heart rate measurements recorded. The four columns can also be interpreted as the median for the bottom 50% (percentile_25), overall median (median), median for the top 50% (percentile_75), and the median for the top 10% (percentile_95) – in terms of how many times the measurement was taken for each patient in the cohort.\n\n\n\nProfile_script_7B\n\n\n\n\n\nGenerates a table of all drugs given in the cohort.\nExample Interpretation\nThe highlighted row shows that acetaminophen was administered to 7,937 total patients which represents 68% of the patients in the cohort. Acetaminophen was administered an average of 2 times per patient with the highest recorded value of 26 administrations for a single patient.\nIt is important to note that these are ingredients - which is why sodium chloride is the most frequent “drug” because most IV drugs contain sodium chloride as an ingredient.\n\n\n\nProfile_script_7C\n\n\n\n\n\nGenerates a table which includes the device concepts included in the cohort and their counts.\nExample Interpretation\nThe highlighted row shows that an oxygen nasal cannula device was used for 9,238 patients in the cohort. That patients count represents 44% of the total cohort. Use of this device was recorded an average of 225.3 times per patient, with a maximum of 7,239 recordings for a single patient, when counting all flowsheet entries.\n\n\n\nProfile_script_7E",
    "crumbs": [
      "Process",
      "Interpretation"
    ]
  },
  {
    "objectID": "interpret.html#omop-table-and-field-basics",
    "href": "interpret.html#omop-table-and-field-basics",
    "title": "Interpretation",
    "section": "OMOP Table and Field Basics",
    "text": "OMOP Table and Field Basics\nAdapted from OHDSI CDM Site: Data Model Conventions \n\nTables\nFor the tables of the main domains of the CDM it is imperative that concepts used are strictly limited to the domain. For example, the CONDITION_OCCURRENCE table contains only information about conditions (diagnoses, signs, symptoms), but no information about procedures. Not all source coding schemes adhere to such rules. For example, ICD-9-CM codes, which contain mostly diagnoses of human disease, also contain information about the status of patients having received a procedure. The ICD-9-CM code V20.3 ‘Newborn health supervision’ defines a continuous procedure and is therefore stored in the PROCEDURE_OCCURRENCE table.\n\n\nFields\nVariable names across all tables follow one convention:\n\n\n\nNotation\nDescription\n\n\n_SOURCE_VALUE\nVerbatim information from the source data, typically used in ETL to map to CONCEPT_ID, and not to be used by any standard analytics. For example, CONDITION_SOURCE_VALUE = ‘787.02’ was the ICD-9 code captured as a diagnosis from the administrative claim.\n\n\n_ID\nUnique identifiers for key entities, which can serve as foreign keys to establish relationships across entities. For example, PERSON_ID uniquely identifies each individual. VISIT_OCCURRENCE_ID uniquely identifies a PERSON encounter at a point of care.\n\n\n_CONCEPT_ID\nForeign key into the Standardized Vocabularies (i.e. the standard_concept attribute for the corresponding term is true), which serves as the primary basis for all standardized analytics. For example, CONDITION_CONCEPT_ID = 31967 contains the reference value for the SNOMED concept of ‘Nausea’\n\n\n_SOURCE_CONCEPT_ID\nForeign key into the Standardized Vocabularies representing the concept and terminology used in the source data, when applicable. For example, CONDITION_SOURCE_CONCEPT_ID = 45431665 denotes the concept of ‘Nausea’ in the Read terminology; the analogous CONDITION_CONCEPT_ID might be 31967, since SNOMED-CT is the Standardized Vocabulary for most clinical diagnoses and findings.\n\n\n_TYPE_CONCEPT_ID\nDelineates the origin of the source information, standardized within the Standardized Vocabularies. For example, DRUG_TYPE_CONCEPT_ID can allow analysts to discriminate between ‘Pharmacy dispensing’ and ’Prescription written\n\n\n\nFor more information, see:\nData Model Conventions\nHow to Calculate Drug Dose \nClinical Data Tables",
    "crumbs": [
      "Process",
      "Interpretation"
    ]
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Support",
    "section": "",
    "text": "Cure ID Concept Mapping Support\n\n\nIdentifying Oxygen Devices in Epic/Clarity\nIdentifying Oxygen Devices Flowsheet Measures to Map to OMOP Concepts\n\n\nGeocoding and Integrating SDOH Data\nTo link geocoded addresses to the Neighborhood Atlas for getting the Area Deprivation Index (ADI) for patients in a dataset, you will typically follow these steps:\n\nPrepare Your Dataset Patient Data: Ensure you have a dataset of patients with addresses. This data should be anonymized to protect patient privacy. Geocoding: Each address needs to be geocoded. Geocoding is the process of converting addresses into geographic coordinates (latitude and longitude).\nGeocoding Addresses Use a Geocoding Service: Tools like Google Maps API, ArcGIS, or OpenStreetMap can be used to geocode addresses. This will give you the precise geographic location for each address. Accuracy Check: Ensure the geocoding is accurate. Incorrect geocoding can lead to wrong ADI assignments.\nUnderstanding the Neighborhood Atlas ADI Overview: The ADI is a measure developed by the Neighborhood Atlas. It provides a ranked and searchable list of neighborhoods according to their level of disadvantage. Data Format: Understand the format of the Neighborhood Atlas data. It typically includes geographical identifiers like census tracts.\nLinking Geocoded Data to the Neighborhood Atlas Match Coordinates with Census Tracts: Use the geographic coordinates to determine the corresponding census tract for each patient. This can be done using GIS software like ArcGIS or QGIS. Cross-Reference with ADI Data: Once you have the census tract for each patient, cross-reference these with the Neighborhood Atlas to find the ADI for each tract.\nIntegrating ADI into Your Dataset Add ADI to Patient Records: For each patient, add the ADI corresponding to their census tract. This step integrates socioeconomic context into your patient data.\n\n\nGeocoding\nThe primary consideration for linking geospatial data like social determinants of health and environmental risk factors with patient data is protecting PHI when geocoding patient home address and location data. Do not use web-based API services for geocoding as they require patient addresses to be sent to an external server for batch geocoding. Geocoding will require software that can match patient addresses to the appropriate shapefiles to determine a precise location and output latitudinal/longitudinal coordinates. Two software solutions for geocoding include: - Use ESRI ArcGIS or a similar program that can perform geocoding locally and has all appropriate shapefiles downloaded. This software is expensive, but many institutions have a license already in place. - Install geocoding software (ex: open-source, Degauss geocoder: https://www.degauss.org/geocoder) locally via manual installation or by installing a docker container.\n\n\nArea Deprivation Index\nThe Area Deprivation Index (ADI) is based on a measure created by the Health Resources & Services Administration (HRSA) over three decades ago, and has since been refined, adapted, and validated to the Census block group neighborhood level by Amy Kind, MD, PhD and her research team at the University of Wisconsin-Madison. It allows for rankings of neighborhoods by socioeconomic disadvantage in a region of interest (e.g., at the state or national level). It includes factors for the theoretical domains of income, education, employment, and housing quality. It can be used to inform health delivery and policy, especially for the most disadvantaged neighborhood groups. “Neighborhood” is defined as a Census block group.\nfrom: https://www.neighborhoodatlas.medicine.wisc.edu/\n\n\nADI as an OHDSI Concept\nADI is not included as an explicit concept in any of the appropriate standard vocabularies. The OHDSI Vocabularies Team recommended that this information be included in the OMOP data as a custom concept in the Observation table. The workflow will be simply to add a line item to the concept mapping table for Area Deprivation Index like the following example: concept_id = 2000000999 concept_code = NA concept_name = Area deprivation index domain = observation vocabulary = Custom is_standard = C include_descendents = False\n\n\n\nOHDSI Tool Suite\nThe Edge Tool Suite are a set of OHDSI tools that should be deployed by the site that provide value around the OMOP CDM. This work was funded by the CURE ID initiative https://cure.ncats.io\nThe OHDSI open source software configured for deployment include:\n\nThe Atlas data science platform\nThe WebAPI backed for Atlas\nThe HADES statistical analysis packages\nThe Data Quality Dashboard\nThe Perseus ETL management system\n\n\nSimplifying the ETL process\nThe OHDSI community has created a series of individual software packages to facilitate the ETL from proprietary EHRs to OMOP, evaluate data quality, define cohorts, and perform analyses. The “Edge Tool” packages these individual tools to facilitate the performance of an OMOP ETL and subsequent use of the data for defining cohorts for observational research. In contrast to registry approaches which ingest data represented in various data models and perform data harmonization centrally, software components of the “Edge Tool” facilitate ETL performance locally at the “edge.” This suite of software aims to drastically reduce the labor and effort required to go from “zero to OMOP.” We anticipate that institutions that use the full suite of offered software will be able to reduce the person-hours required for an OMOP ETL to as little as 50 hours.\n\n\nSoftware components\nThe Edge Tool encompasses the Perseus ETL management solution, the HADES R analysis package within an RStudio Server R integrated development environment, and the ATLAS cohort discovery tool with WebAPI web services integration (Figure). The Perseus graphic-user interface (GUI) approach provides source-to-concept mapping for the ETL, with assisted extraction of data from EHR such as flowsheets (vital signs, nursing assessments), test measurements, and diagnoses. Rather than performing a series of SQL queries with wildcards to identify data elements of interest from primary source EHR tables,users may enter desired data element terms into a browser text field which are then matched using term similarity to source table entries.Users may then evaluate the completeness and quality of the ETL using the Data Quality Dashboard which performs &gt;3,000 individual data quality checks on the OMOP-formatted data and is reported through a web-based reporting system.\nIn tandem with Perseus, OHDSI HADES and OHDSI ATLAS are the two projects within the Edge Tool that allow for advanced analysis once data has been harmonized with the OMOP CDM, such as generating cohorts for research, patient level prediction, treatment pathways, large scale population analytics, automated reporting and, optionally, participation in OHDSI network studies.The OHDSI applications within the Edge Tool have been containerized using OHDSI Broadsea, allowing for even easier deployment. Current use of the Edge Tool has proven promising and while limitations still exist - e.g., not currently capable of extracting data from unstructured fields such as notes or loose text - further process optimization and tool development will reduce this implementation time and effort further.\n\n\nWays to deploy the software\n\nCloud vendor software configured for use.\n\nOHDSI on Azure (Includes Perseus, Atlas, and Hades)\nOHDSI on AWS (Includes Atlas and Hades)\n\nBroadsea provides a set of docker containers that ease the cost of implementation\n\nBroadsea (Includes Atlas and Hades)\n\nSites can compile the tools from the source repositories\n\n\n\nOHDSI Specific\nhttps://github.com/OHDSI/CommonDataModel\nhttps://github.com/OHDSI/Broadsea\nhttps://github.com/OHDSI/Athena\n\n\nThe ETL Process\nhttps://github.com/OHDSI/Perseus\nhttps://github.com/OHDSI/WhiteRabbit\nhttps://github.com/OHDSI/Usagi\n\n\nATLAS and Cohort Discovery\nhttps://github.com/OHDSI/Atlas\nhttps://github.com/OHDSI/WebAPI\n\n\nBroadsea\nhttps://www.youtube.com/watch?v=a9ZJURNRbUg\n\n\nData Analysis\nhttps://github.com/OHDSI/Achilles\nhttps://github.com/OHDSI/Hades\nhttps://github.com/OHDSI/DataQualityDashboard\n\n\n\nBest Practices\nData Quality Dos and Don’ts\n\nDo install the Data Quality Dashboard early on in the process.\nDon’t include source values in your export - they might include PHI.\nDon’t forget to check GitHub for the most recent version of the script before you run it.\nDon’t send your data to the coordinating center until the tech team has a chance to review it with you in a live session.\nDuplicated results have been reported at some sites when running script 02_CURE_ID_ALL_Tables.sql. However, at this time no root cause has been found. There is some belief that adding DISTINCT to the various SELECT statements could resolve the issue, while there is some concern over the latest updates to script 00_CURE_ID_create_concept_table.sql as it has standard concepts as well as standard descendants. Be sure to review your data carefully and report any signs of duplication so that it can be investigated.\n\n\n\nManuscripts\nHeavner SF, Anderson W, Kashyap R, Dasher P, Mathé EA, Merson L, Guerin PJ, Weaver J, Robinson M, Schito M, Kumar VK, Nagy P. A Path to Real-World Evidence in Critical Care Using Open-Source Data Harmonization Tools. Crit Care Explor. 2023 Apr 3;5(4):e0893. doi: 10.1097/CCE.0000000000000893. PMID: 37025303; PMCID: PMC10072311.\n\n\nWebinars\n\n\n\nOMOP Scripts for Epic\n“The Spectrum Code”: scripts and documentation created by Roger Carlson at Corewell Health\nRUMC OMOP transition scripts from Clarity, Caboodle: Code created by Rush University Medical Center\n\n\nUsing synthetic data\nMIMIC-IV 100-patient demo dataset based on MIMIC to create a OMOP instance\nSynthea GitHub site with files to use the synthetic patient generator Synthea\nEunomia LInk to the Eunomia GitHub.io site with instructions and standard dataset files\n\n\nUseful Resources\nWeb site for the OHDSI community: http://www.ohdsi.org\nThe Book of OHDSI: What is OHDSI and why should I care?\nEHDEN Academy : EHDEN Academy is a site with courses for developing skills working with OHDSI\nTutorials & Workshops : Tutorial sessions 1-8 provide a comprehensive overview from vocabularies and creating cohorts to prediction\nOHDSI Forums : Searchable, active user community\nOHDSI Community Dashboard : Tracks publications, citations, researchers and activity within the OHDSI community\nClinical Registry Efforts Within OHDSI (Sept. 13 Community Call): Video discussing Perseus and Broadsea\nOHDSI-in-a-Box on GitHub : A learning environment created for the OHDSI community\nIntegrating Flowsheet Data in OMOP Common Data Model for Clinical Research Paper written by informatics teams at Stanford University and The Hospital for Sick Children\nGuide to privacy issues in OMOP journey: Article outlining how to manage protected health information\nDQD GitHub repository for Data Quality Dashboard tool\nPheKB A phenotype repository\nAnalyze observational patient data by using OHDSI with the OMOP CDM Microsoft guide to OMOP CDM\nOHDSI on Azure GitHub Automation code and documentation for deploying OHDSI CDM in Azure\nOHDSI/Perseus GitHub site OHDSI/Perseus on GitHub\nHow to develop capacity for observational research within a health system Presentation on building capacity from 2022 OHDSI Collaborator Showcase",
    "crumbs": [
      "Support",
      "Support"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Getting Started",
    "section": "",
    "text": "This site is designed to provide guidance, scripts and resources for sites transitioning data to OMOP common data model as part of CURE ID.\nCURE ID is a platform designed and developed by the US Food and Drug Administration (FDA) and the National Institutes of Health (NIH) National Center for Translational Sciences (NCATS) to capture real world data (RWD) about how existing drugs are used in new ways (e.g., drug repurposing) to treat diseases of high unmet clinical need. The documentation on this site is part of a project funded by the US Department of Health and Human Services (HHS) Assistant Secretary for Planning and Evaluation (ASPE)’s Patient-Centered Outcomes Research Trust Fund (under Interagency Agreement #75F40121S35006) to develop and disseminate tools facilitating the extraction of RWD from the electronic health record (EHR).",
    "crumbs": [
      "Intro",
      "Getting Started"
    ]
  },
  {
    "objectID": "intro.html#welcome",
    "href": "intro.html#welcome",
    "title": "Getting Started",
    "section": "",
    "text": "This site is designed to provide guidance, scripts and resources for sites transitioning data to OMOP common data model as part of CURE ID.\nCURE ID is a platform designed and developed by the US Food and Drug Administration (FDA) and the National Institutes of Health (NIH) National Center for Translational Sciences (NCATS) to capture real world data (RWD) about how existing drugs are used in new ways (e.g., drug repurposing) to treat diseases of high unmet clinical need. The documentation on this site is part of a project funded by the US Department of Health and Human Services (HHS) Assistant Secretary for Planning and Evaluation (ASPE)’s Patient-Centered Outcomes Research Trust Fund (under Interagency Agreement #75F40121S35006) to develop and disseminate tools facilitating the extraction of RWD from the electronic health record (EHR).",
    "crumbs": [
      "Intro",
      "Getting Started"
    ]
  },
  {
    "objectID": "intro.html#introduction",
    "href": "intro.html#introduction",
    "title": "Getting Started",
    "section": "Introduction",
    "text": "Introduction\nThe goals of OMOP are to gain better understanding of human health by improving our ability to analyze observational health data.\nHealth data is stored by individual health systems in unique ways which limits the ability to collaborate and learn from larger populations. This is a problem because certain clinical conditions are infrequent and it is important to have sufficient number of cases to perform statistical tests. De-identified data shared across institutions has the promise of allowing scientists to develop important insights about health which is the motivation to enable greater collaboration.\n\nWhat is a common data model?\nA common data model (CDM) allows multiple health care systems with their individual databases to join forces creating greater populations which can power more compelling scientific studies. A simple way to think about this is the difficulty of finding the silverware drawer in a new kitchen – if there is a unifying rule for where the silverware drawer is located in every kitchen (immediately to right of the sink) it makes it possible to find this much easier. A common data model creates a system so that data elements like “systolic blood pressure” or “sepsis” are recorded and organized in the same way. OMOP stands for Observational Medical Outcomes Partnership and is the common data model of the Observational Health Data Sciences and Informatics program.\n\n\nWhat is an ETL?\nETL stands for Extract, Transform, and Load. Essentially this is the process of mapping data from one system to another. Please see [The Book of OHDSI, Chapter 6] (https://ohdsi.github.io/TheBookOfOhdsi/ExtractTransformLoad.html).",
    "crumbs": [
      "Intro",
      "Getting Started"
    ]
  },
  {
    "objectID": "intro.html#getting-started",
    "href": "intro.html#getting-started",
    "title": "Getting Started",
    "section": "Getting started",
    "text": "Getting started\nThe code for the CURE ID project is hosted on GitHub. GitHub is a web-based platform that allows developers to host, review, and collaborate on code repositories. It is widely used for version control and source code management, and it provides features such as issue tracking, wikis, and project management tools to facilitate team collaboration. \nThe repository containing the code and concept sets can be accessed at OHDSI/CureIdRegistry There are four branches within the repository that differ only in the clinical variables included in the cohort curation scripts. Be sure to select the appropriate branch based on individual health system data and ETL capacity:\n\nMain branch: fundamental set of variables for Registry submission - demographics, comorbidities, vitals, labs, medications, vaccinations, oxygen devices, viral assays, and COVID complications.\nRefresh Basic: the main branch variables with additional concepts to allow for Charlson Comorbidity Index calculation\nRefresh Advanced: the refresh basic branch variables with additional concepts for Area Deprivation Index calculation (this branch requires Geocoding patient addresses to determine Census Blocks)\nMain CDM v5.3: this is the same set of variables included in the main branch but with cohort curation scripts written for the OMOP CDM version 5.3 (there are four fields names that changed from version 5.3 to 5.4)",
    "crumbs": [
      "Intro",
      "Getting Started"
    ]
  },
  {
    "objectID": "intro.html#cure-id-technical-support-checklist",
    "href": "intro.html#cure-id-technical-support-checklist",
    "title": "Getting Started",
    "section": "CURE ID technical support checklist",
    "text": "CURE ID technical support checklist\n\nCore site team identified and technical kickoff call scheduled\nDetermine feasibility of using Edge Tool Suite\nIf using Edge Tool Suite is not possible, has the site determined a path forward, for example using Spectrum Health Scripts?\nMembers of core team send proof of course completion to Danielle Boyce for the following free EHDEN academy courses:\n\nCourse: OMOP CDM and Standardised Vocabularies (ehden.eu)\nCourse: Extract, Transform and Load (ehden.eu)\n\nSite Completes CURE ID Manual OMOP Data Mapping Template\nJHU reviews steps for performing ETL process by walking through GitHub scripts\nMeetings with JHU software contractors arranged, if needed\nSite confirms that they are using most recent GitHub scripts before proceeding\nData Quality Dashboard Run\nJSON and script output sent to Danielle Boyce\nDQD and concept counts approved or issues identified and reviewed with technical team\nDQD and concept counts re-run and approved by JHU technical team\nRun CURE ID scripts (see OMOP Cohort Creation and De-identification Guide)\nDe-identified data exported to CSV file\nJHU/C-Path technical team reviews CSV files before transfer\nAny caveats in the data documented in Data Export Cover Sheet\nData transfer arrangements made by contacting Smitty Heavner",
    "crumbs": [
      "Intro",
      "Getting Started"
    ]
  },
  {
    "objectID": "intro.html#omop-extract-transform-and-load-guide",
    "href": "intro.html#omop-extract-transform-and-load-guide",
    "title": "Getting Started",
    "section": "OMOP Extract, Transform, and Load Guide",
    "text": "OMOP Extract, Transform, and Load Guide\n\nOHDSI ETL Resources\n\nOHDSI Wiki: ETL Creation Best Practices\nBook of OHDSI (Ch. 6): Extract Transform Load\nEHDEN Academy: OMOP CDM and Standardised Vocabularies\nEHDEN Academy: Extract, Transform and Load\nEHDEN Academy: Introduction to Usagi & Code Mappings for an ETL\n\n\n\nOHDSI ETL Steps\n\nFind your people.\n\nAssemble ETL team: both data experts, medical experts, CDM/vocabulary experts\nAssign persons with medical knowledge to create code mappings\nAssign persons with technical knowledge to implement the ETL\nSchedule regular meetings for quality control maintenance\n\nUnderstand your data.\n\nTake inventory of source data (tools: White Rabbit)\n\nList of tables in database\nList fields in each table\nList distinct values of each field\nSummarize the frequency of each value of each field.\n\nDefine relationships between source data tables and fields (tools: Rabbit-in-a-Hat)\n\nRecord both relationship definition decisions and reasoning behind these decisions\n\nDetermine standardized vocabularies that already exist in your source data (ICD-10, CPT, HCPCS, LOINC, etc.)\n\nMany commonly used standardized coding systems have already been mapped to the OMOP vocabulary – utilize the work done by others across the OHDSI community to accelerate the process of mapping your data systems to OMOP.\n\nDetermine the coding systems in your source data that are proprietary or not already mapped to OMOP (proprietary patient/visit identifiers, account numbers, charge codes, etc.)\n\nMap your codes to OMOP concepts.\n\nSummarize the frequency of each code from your source data code sets that will require mapping to OMOP concepts.\nCreate your source data to OMOP mapping. (tools: Usagi)\n\nAssign this task to the ETL team members with appropriate medical knowledge to discern which codes are most synonymous based on their descriptions. Medical knowledge is key for this step as semantic understanding of clinical descriptions is required to make decisions on mapping source data concepts to OMOP concepts.\nStart with the most frequently used codes and determine your threshold of code frequency to include in the mapping.\nFocus on a particular project or clinical domain to limit the scope of data needed for capture and conversion to OMOP.\nUtilize the Usagi tool for mapping suggestions and searching based on similarity of code descriptions.\n\n\nOMOPify your data!\n\nDetermine the technology and software used or approved at your site for data storage, querying, and transfer. Determine the tools and technologies that team members and internal staff have expertise in.\nGenerate the OMOP DDLs\n\nUsing R: https://github.com/OHDSI/CommonDataModel\nUsing SQL: https://github.com/OHDSI/CommonDataModel/tree/v5.4.0/inst/ddl/5.4\n\nImplement the ETL.\n\nAssign this task to the ETL team members with technical knowledge and permission for accessing and extracting source data and writing to a database.\nMany tools and technologies can be used for this step. Utilize the existing tools, technologies, and expertise of your ETL team and internal staff.\n\n\nEvaluate your data.\n\nInvolve everyone in the evaluation and maintenance of ETL and data quality.\nReview the ETL design documentation, computer code used in implementation, and concept mappings\nPerform a manual audit using a sample of patients from both source data and derived OMOP data\nCompare summary level counts of key fields between source data and OMOP derived data. (tools: Achilles)\n\n\n★ Ask for help along the way!\nThe CURE ID support team is here to help you. We also encourage you to connect with the OHDSI community to find others with experience, expertise, and guidance for each step of your ETL to OMOP journey. The open, collaborative community of OHDSI is the most powerful tool at your disposal. Use it (us)!\n\n\nPlaces to Connect\n\nOHDSI.org: https://www.ohdsi.org/\nOHDSI Wiki: https://www.ohdsi.org/web/wiki/doku.php\nOHDSI Forums: https://forums.ohdsi.org/\nOHDSI Workgroups: https://www.ohdsi.org/workgroups/",
    "crumbs": [
      "Intro",
      "Getting Started"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CURE ID",
    "section": "",
    "text": "Collaborative OMOP Concept Mapping Process\n\nCureID clinical informaticists work with each site to manually map internal concepts to OMOP concepts outlined for capture in the project plan.\nThe combined concepts from all sites are maintained as a single, updated concept set using the OHDSI ATLAS open-source tool.\nAll concepts currently identified by the work between CureID staff and each site, and all corresponding descendant concepts are exported from ATLAS as .json or .csv files for use in cohort creation, profiling, and clinical registry submission.",
    "crumbs": [
      "Intro",
      "CURE ID"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is designed to provide guidance, scripts and resources for sites participating in transitioning data to OMOP common data model as part of CURE ID\nThis work was funded by the CURE ID initiative https://cure.ncats.io\nCure ID Collaborators",
    "crumbs": [
      "Support",
      "About"
    ]
  },
  {
    "objectID": "about.html#footnotes",
    "href": "about.html#footnotes",
    "title": "About",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nJohns Hopkins School of Medicine↩︎",
    "crumbs": [
      "Support",
      "About"
    ]
  }
]